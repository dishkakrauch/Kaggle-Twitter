{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42f71dbd929db08d94fa71caf6b389f60cf325b7"},"cell_type":"markdown","source":"# Import packages"},{"metadata":{"trusted":true,"_uuid":"e5bbeb008457c62774388059f4d310c18792b624"},"cell_type":"code","source":"import re\nimport string\nimport time\nimport gc\nimport sys\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.ensemble import *\nfrom sklearn.cluster import *\nfrom sklearn.linear_model import *\nfrom gensim.models import *\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\nfrom nltk.tokenize import WordPunctTokenizer, TweetTokenizer\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nimport seaborn as sns\nimport matplotlib as plt\nplt.rcParams[\"figure.figsize\"] = (20,10)\nimport warnings\nwarnings.filterwarnings('ignore')\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67b0cf03ba8da35fbc6a2059fab1d50c965fdc63"},"cell_type":"markdown","source":"# Load data and check stratification"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"X_train = pd.read_csv(\"../input/train.csv\", encoding='latin1')\nX_test = pd.read_csv(\"../input/test.csv\", encoding='latin1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da6d26f6dc843676207f1fc153cc048e0117a6fc"},"cell_type":"code","source":"X_train['Sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6ddef642c6da6f85b337a1815d6e3db78dcb7eb"},"cell_type":"code","source":"X_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1e852eff90821da84aea16d915c92769ffdeb4ba"},"cell_type":"code","source":"X_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea23adbc39c71ef7cdb07943fc0b4327295636fa"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f92621ea092df2157bc2a4f7bc36f85fc097eef"},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5257178d87154dd37ae19bad9af5b339d1f2add1"},"cell_type":"markdown","source":"# Set functions for tweet cleaning"},{"metadata":{"trusted":true,"_uuid":"9b4fc2baed8e588186221aee436e7731f95a9ca5"},"cell_type":"code","source":"def clear_tweets(s):\n    tok = WordPunctTokenizer()\n    porter = PorterStemmer()\n    lancaster = LancasterStemmer()\n    wordnet_lemmatizer = WordNetLemmatizer()\n    nickname = r'@[A-Za-z0-9]+'\n    url = r'https?://[A-Za-z0-9./]+'\n    hashtag = r'#'\n    pattern = r'|'.join((nickname, url, hashtag))\n    s = BeautifulSoup(s).get_text()\n    s = re.sub(pattern, '', s)\n    s = re.sub('[^a-zA-Z]', ' ', s)\n    s = s.lower()\n    tockens = tok.tokenize(s)\n    stems = []\n    for t in tockens:\n        #stems.append(porter.stem(t))\n        #stems.append(lancaster.stem(t))\n        stems.append(wordnet_lemmatizer.lemmatize(t, pos=\"v\"))\n    return (' '.join(stems)).strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"58a30ce2599f75d43f4439b08136afaa3298f1d5"},"cell_type":"code","source":"stopwords_english = stopwords.words('english')\nstemmer = PorterStemmer()\n\nemoticons_happy = set([\n    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n    '<3'\n    ])\nemoticons_sad = set([\n    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n    ':c', ':{', '>:\\\\', ';('\n    ])\nemoticons = emoticons_happy.union(emoticons_sad)\n\ndef clear_tweets(tweet):\n    #removing vibes like retweet, nicname, hastags and etc.\n    tweet = re.sub(r'\\$\\w*', '', tweet)\n    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n    tweet = re.sub(r'#', '', tweet)\n    #tokenize tweets\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n    tweet_tokens = tokenizer.tokenize(tweet)\n    \n    tweets_clean = []    \n    for word in tweet_tokens:\n        if (#word not in stopwords_english and\n              #word not in emoticons and\n                word not in string.punctuation):\n            #tweets_clean.append(word)\n            stem_word = stemmer.stem(word) # stemming word\n            #stem_word = stemmer.lemmatize(word, pos='v') # stemming word\n            tweets_clean.append(stem_word)\n    \n    return (' '.join(tweets_clean)).strip()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7595c88217410ab25f90cd3ae239e00fa11643f"},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true,"_uuid":"aaaa14eba15c08540d21ef2f3cbc41fb2b463e6b"},"cell_type":"code","source":"tweet = 'RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning https://chapagain.com.np'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"514353347727ae29dd156f8cde5bd200aec9509f"},"cell_type":"code","source":"clear_tweets(tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe9dcde1f25e994582a95095c4e49333732f550"},"cell_type":"code","source":"list(X_train['SentimentText'].head(5).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85650d7d60028ef6599f249c5535358dcccc8811"},"cell_type":"code","source":"clear_tweets(X_train['SentimentText'][3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e9151d41439db2b60b0c054b61f3cf9f0f362d9"},"cell_type":"markdown","source":"# Processing train data"},{"metadata":{"trusted":true,"_uuid":"07be2e2cb9d25e8dad14f3c267619a4c79dfcc2f","scrolled":true},"cell_type":"code","source":"%%time\n\nX_train_processed = []\ncount = X_train.shape[0]\nfor i, t in enumerate(X_train['SentimentText'].values):\n    X_train_processed.append(clear_tweets(t))\n    if (i+1)%10000==0:\n        print('Processed:', i+1, '\\n', 'of', count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4088284e9c5ca1a6768db795ee38db171c6b464a"},"cell_type":"markdown","source":"# Split data for features and compare data before and after cleaning"},{"metadata":{"trusted":true,"_uuid":"851fffbcf02f5f69b765c258eaecf929cd2c933a"},"cell_type":"code","source":"y = X_train['Sentiment'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ef90b7c5e19baa9136a4267346bc9e2a3d3a17b"},"cell_type":"code","source":"list(X_train['SentimentText'].head(10).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"0cd7e8c733a28be4f066b93e4690eb779d77d698"},"cell_type":"code","source":"X_train_processed[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7f8f3893eb7b5cee3a9c5adfa4794909edf8d72"},"cell_type":"markdown","source":"# Using TFIDF"},{"metadata":{"trusted":true,"_uuid":"e3f80bf57d254359577aeaab8e57be32c2bad4b4","scrolled":true},"cell_type":"code","source":"%%time\n\nX_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_train_processed, y, test_size=.25)\n\nvectorizer = TfidfVectorizer(input='content',\n                             encoding='latin1',\n                             decode_error='strict',\n                             strip_accents=None,\n                             lowercase=True,\n                             preprocessor=None,\n                             tokenizer=None,\n                             analyzer='word',\n                             #stopwords didn't work\n                             stop_words=None,\n                             #token_pattern='(?u)\\b\\w\\w+\\b',\n                             ngram_range=(1, 5),\n                             max_df=.9,\n                             min_df=3,\n                             max_features=100000,\n                             vocabulary=None,\n                             binary=False,\n                             dtype='float64',\n                             norm='l2',\n                             use_idf=True,\n                             smooth_idf=True,\n                             sublinear_tf=False)\n\nX_train_cv = vectorizer.fit_transform(X_train_cv)\nX_test_cv = vectorizer.transform(X_test_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afac2d681428c768b516d223ff8255e079385129","scrolled":true},"cell_type":"code","source":"%%time\n\nLR = LogisticRegression(penalty='l2'\n                        , dual=False\n                        , tol=0.0001\n                        , C=1.0\n                        , fit_intercept=True\n                        , intercept_scaling=1\n                        , class_weight=None\n                        , random_state=0\n                        , solver='liblinear'\n                        , max_iter=100\n                        , multi_class='ovr'\n                        , verbose=0\n                        , warm_start=False\n                        , n_jobs=-1)\n\nLR.fit(X_train_cv, y_train_cv)\npredict = LR.predict(X_test_cv)\nprint(f1_score(y_test_cv, predict))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deb04d964a32adcb9cb0cc85a2e956eb93450655"},"cell_type":"markdown","source":"# Debug"},{"metadata":{"trusted":true,"_uuid":"0ae32d7c531c2bd4752ff2f2e4fdeaac54c9175b"},"cell_type":"code","source":"i = 100\nfor n, t in enumerate(X_test_processed[:i]):\n    if y_test_cv[n-1]!=predict[n-1]:\n        print(n,y_test_cv[n-1], t)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aabce620f48ed03b6d10a7a4333aefe487d84f19"},"cell_type":"markdown","source":"# Processing test data"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"845629ffbcbc1f5c4ebf1d961b959695cd424737"},"cell_type":"code","source":"%%time\n\nX_test_processed = []\ncount = X_test.shape[0]\nfor i, t in enumerate(X_test['SentimentText'].values):\n    X_test_processed.append(clear_tweets(t))\n    if (i+1)%10000==0:\n        print('Processed:', i+1, '\\n', 'of', count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d054d58d88cb915487d285379eb5d1bd910a33e"},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true,"_uuid":"3460b3d9304d3142c1bc6191246a753ffcff814d"},"cell_type":"code","source":"predict = LR.predict(vectorizer.transform(X_test_processed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d02701ab8cbba23e6c7ab57a60b09a43223aaa00"},"cell_type":"code","source":"output = pd.DataFrame( data={\"ItemID\":X_test[\"ItemID\"], \"Sentiment\":predict} )\noutput.to_csv(\"Twitter_result.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b10c4decdac93f5c798db14e0ea57b9c12897c4"},"cell_type":"code","source":"# G","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99d673c03198cb162f9e6f2bdb3ab6379f8775e3","scrolled":true},"cell_type":"code","source":"#%%time\n#%env JOBLIB_TEMP_FOLDER=/tmp\n#\n##using gpu for grid search cv\n#\n#params = {\n#    'penalty': ['l1', 'l2'],\n#    'max_iter': [100, 150, 250, 500],\n#    'tol': [.0001, .001, .01, 1.0],\n#    'C': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0]\n#}\n#\n#cv = GridSearchCV(estimator=LR, param_grid=params, n_jobs=-1, cv=5, verbose=1)\n#cv.fit(X=X_train_cv, y=y_train_cv)\n\n#print(cv.best_params_)\n#print(f1_score(y_test_cv, cv.best_estimator_.predict(X_test_cv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08f7ad49a52e3f7d1f796279bc70cd55633190ca"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c45a0d2708efe2e466dd59fc647e2ce920474504"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04444ab792ce0c064f420d0944ac31624f136fd8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b9a5ffb1ad0463812995f87cd573b9bfa78a0d0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"350c6fada715c383f19ed0c529ba5cd6c738ba63"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3cce55debdf6a589fc0e1d75314f7c79c57aa34"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e1a387eae7e0b5e7538fe14b195f779a0f90cb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"129d26ac9ec5757adaafcfdd451bbad53485b293"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0ac6f3bc8aa6657d53ae433c0dfaf552b7ad079"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4f982a46013abec775af360887edb56f6ba3279"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74a6a3442b625bff85dbf90650944813a65860f5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5222ee4758e80823895ead236d0c0d17999eef44"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ae64d0a4b954419edf0347d0a89f9a67fbfed19"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4c2d3d6971de5cab1ee624be7fe0c90a71b9ab5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5acb6b08255c6b378b630c6793d7e29a322cbe2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9bc2fbaa70e87d9f344b4bc57d2d9fcadd846bf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28480f3118b9d9d9cfc65be68b48c7461c20ac36"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60486376c2f6735844fdb4e158c424a6ef4a9459"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d9ff5eeaab25f0ac25a46e7c097c6ccdc11ebcd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1609c1a65103030083e6ad777682d2496691b9f9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c45473e098911e89301d8d54d8087f97f87fdafc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"183ac2d5bd0ec028310df5cc03fcebd123cfab3a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"197e56a27bc57aadf6c075f7a9c9fb55147d1ee5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fa37abda5732e17dd634d9ed2377c8958dc3d0a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}